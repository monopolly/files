package file

import (
	"fmt"
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestLZ4(t *testing.T) {
	a := assert.New(t)
	_ = a

	co := compressLZ4([]byte(`Начал играться с анализом языковых данных и такой вопрос возник - как обычно хранят данные перед обработкой? Есть, к примеру, сотня гигов текстовых файлов, данные в которых разделены табами. И я пока не знаю, что именно мне в них понадобится. Можно их распарсить и залить в постгрес или монгу, а в дальнейшем брать оттуда огромнейшие выборки (использовать курсор?) и что-то с ними делать. Или оставить как есть, а как что понадобится - парсить каким-нибудь хадупом или чем-то вроде того.`))
	fmt.Println(len(co), string(co))

	un := uncompressLZ4(co)
	fmt.Println(string(un))
}

func BenchmarkLZ4comp(b *testing.B) {
	for n := 0; n < b.N; n++ {
		compressLZ4([]byte(`Начал играться с анализом языковых данных и такой вопрос возник - как обычно хранят данные перед обработкой? Есть, к примеру, сотня гигов текстовых файлов, данные в которых разделены табами. И я пока не знаю, что именно мне в них понадобится. Можно их распарсить и залить в постгрес или монгу, а в дальнейшем брать оттуда огромнейшие выборки (использовать курсор?) и что-то с ними делать. Или оставить как есть, а как что понадобится - парсить каким-нибудь хадупом или чем-то вроде того.`))
	}
}

func BenchmarkLZ4un(b *testing.B) {
	co := compressLZ4([]byte(`Начал играться с анализом языковых данных и такой вопрос возник - как обычно хранят данные перед обработкой? Есть, к примеру, сотня гигов текстовых файлов, данные в которых разделены табами. И я пока не знаю, что именно мне в них понадобится. Можно их распарсить и залить в постгрес или монгу, а в дальнейшем брать оттуда огромнейшие выборки (использовать курсор?) и что-то с ними делать. Или оставить как есть, а как что понадобится - парсить каким-нибудь хадупом или чем-то вроде того.`))
	for n := 0; n < b.N; n++ {
		uncompressLZ4(co)
	}
}
